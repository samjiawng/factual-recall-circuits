{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factual Recall Circuit Discovery - Interactive Tutorial\n",
    "\n",
    "This notebook walks through the process of discovering factual recall circuits in Gemma 2B using attribution graphs and sparse autoencoders.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from circuit_discovery import CircuitDiscovery, Circuit\n",
    "from testing_pipeline import CircuitTester, FeatureHypothesis\n",
    "from utils import (\n",
    "    visualize_circuit, \n",
    "    compare_circuits,\n",
    "    plot_testing_results\n",
    ")\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == 'cpu':\n",
    "    print(\"WARNING: Running on CPU will be very slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Initialize Discovery System\n",
    "\n",
    "Load Gemma 2B and set up the circuit discovery pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize circuit discovery\n",
    "print(\"Loading Gemma 2B...\")\n",
    "discovery = CircuitDiscovery(device=device)\n",
    "print(\"✓ Model loaded successfully!\")\n",
    "\n",
    "# Check model details\n",
    "num_layers = len(discovery.model.model.layers)\n",
    "print(f\"\\nModel has {num_layers} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Create Factual Dataset\n",
    "\n",
    "Define prompts for different types of factual knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset of factual prompts\n",
    "dataset = {\n",
    "    'entity_location': [\n",
    "        {'clean': 'The Eiffel Tower is located in Paris',\n",
    "         'corrupted': 'The Eiffel Tower is located in London'},\n",
    "        {'clean': 'Mount Everest is in the Himalayas',\n",
    "         'corrupted': 'Mount Everest is in the Alps'},\n",
    "        {'clean': 'The Colosseum is in Rome',\n",
    "         'corrupted': 'The Colosseum is in Athens'},\n",
    "    ],\n",
    "    \n",
    "    'capital_country': [\n",
    "        {'clean': 'The capital of France is Paris',\n",
    "         'corrupted': 'The capital of France is Berlin'},\n",
    "        {'clean': 'Tokyo is the capital of Japan',\n",
    "         'corrupted': 'Tokyo is the capital of China'},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Display dataset statistics\n",
    "print(\"Dataset Overview:\")\n",
    "for fact_type, prompts in dataset.items():\n",
    "    print(f\"  {fact_type}: {len(prompts)} prompt pairs\")\n",
    "print(f\"\\nTotal: {sum(len(p) for p in dataset.values())} prompt pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Test Attribution Methods\n",
    "\n",
    "Let's first test the attribution methods on a single example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test activation patching\n",
    "test_clean = \"The Eiffel Tower is in Paris\"\n",
    "test_corrupted = \"The Eiffel Tower is in London\"\n",
    "\n",
    "print(\"Testing activation patching across layers...\\n\")\n",
    "\n",
    "layer_effects = {}\n",
    "for layer_idx in range(0, num_layers, 3):  # Test every 3rd layer\n",
    "    effect = discovery.attribution_graph.activation_patching(\n",
    "        test_clean, test_corrupted, layer_idx, -1\n",
    "    )\n",
    "    layer_effects[layer_idx] = effect\n",
    "    print(f\"Layer {layer_idx:2d}: effect = {effect:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(layer_effects.keys(), layer_effects.values(), color='steelblue', alpha=0.7)\n",
    "plt.xlabel('Layer', fontsize=12)\n",
    "plt.ylabel('Patching Effect', fontsize=12)\n",
    "plt.title('Activation Patching Effect Across Layers', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMost important layer: {max(layer_effects, key=layer_effects.get)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train Sparse Autoencoders\n",
    "\n",
    "Train SAEs on important layers to extract interpretable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect training prompts\n",
    "training_prompts = []\n",
    "for prompts in dataset.values():\n",
    "    training_prompts.extend([p['clean'] for p in prompts])\n",
    "\n",
    "print(f\"Training SAEs on {len(training_prompts)} prompts...\\n\")\n",
    "\n",
    "# Train SAEs for middle layers (most important for factual recall)\n",
    "important_layers = [8, 12, 16]  # Adjust based on your model\n",
    "\n",
    "for layer_idx in important_layers:\n",
    "    if layer_idx < num_layers:\n",
    "        print(f\"\\nTraining SAE for layer {layer_idx}...\")\n",
    "        sae = discovery.train_sparse_autoencoder(\n",
    "            layer_idx=layer_idx,\n",
    "            training_prompts=training_prompts,\n",
    "            epochs=5  # Increase for better results\n",
    "        )\n",
    "        print(f\"✓ SAE trained for layer {layer_idx}\")\n",
    "\n",
    "print(\"\\n✓ All SAEs trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Discover Circuits\n",
    "\n",
    "Now discover circuits for each fact type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover circuits (SAEs already trained)\n",
    "print(\"Discovering circuits...\\n\")\n",
    "\n",
    "circuits = []\n",
    "for fact_type, prompts in dataset.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Discovering circuit for: {fact_type}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    circuit = discovery.discover_circuit(\n",
    "        fact_prompts=prompts,\n",
    "        fact_type=fact_type,\n",
    "        threshold=0.01\n",
    "    )\n",
    "    \n",
    "    circuits.append(circuit)\n",
    "    \n",
    "    print(f\"\\n✓ Found circuit with:\")\n",
    "    print(f\"   {len(circuit.nodes)} nodes\")\n",
    "    print(f\"   {len(circuit.edges)} edges\")\n",
    "    print(f\"   Attribution score: {circuit.attribution_score:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total circuits discovered: {len(circuits)}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Visualize Circuits\n",
    "\n",
    "Create visualizations of discovered circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each circuit\n",
    "for circuit in circuits:\n",
    "    print(f\"\\nVisualizing: {circuit.name}\")\n",
    "    fig = visualize_circuit(circuit, figsize=(14, 8))\n",
    "    plt.show()\n",
    "\n",
    "# Compare all circuits\n",
    "print(\"\\nComparing all circuits...\")\n",
    "fig = compare_circuits(circuits, figsize=(14, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Test Hypotheses\n",
    "\n",
    "Create and test hypotheses about circuit features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tester\n",
    "tester = CircuitTester(discovery)\n",
    "\n",
    "# Create example hypotheses\n",
    "hypotheses = []\n",
    "\n",
    "for circuit in circuits:\n",
    "    # Get first few nodes\n",
    "    for i, node in enumerate(circuit.nodes[:3]):\n",
    "        hyp = FeatureHypothesis(\n",
    "            feature_id=node,\n",
    "            hypothesis=f\"{circuit.fact_type} detector (node {i})\",\n",
    "            test_prompts=[\n",
    "                \"Paris is in France\",\n",
    "                \"Tokyo is in Japan\",\n",
    "                \"London is in England\"\n",
    "            ],\n",
    "            control_prompts=[\n",
    "                \"The sky is blue\",\n",
    "                \"Two plus two equals four\",\n",
    "                \"Water is wet\"\n",
    "            ]\n",
    "        )\n",
    "        hypotheses.append(hyp)\n",
    "\n",
    "print(f\"Testing {len(hypotheses)} hypotheses...\\n\")\n",
    "\n",
    "# Test hypotheses\n",
    "results = []\n",
    "for hyp in hypotheses:\n",
    "    try:\n",
    "        result = tester.validator.test_hypothesis(hyp, verbose=True)\n",
    "        results.append(result)\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipped: {e}\\n\")\n",
    "\n",
    "# Summary\n",
    "if results:\n",
    "    passed = sum(r.passed for r in results)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing Summary: {passed}/{len(results)} hypotheses passed\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Analyze Circuit Properties\n",
    "\n",
    "Dive deeper into circuit characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze circuit properties\n",
    "print(\"Circuit Analysis:\\n\")\n",
    "\n",
    "for circuit in circuits:\n",
    "    print(f\"\\n{circuit.name}:\")\n",
    "    \n",
    "    # Node distribution across layers\n",
    "    layer_counts = {}\n",
    "    for node in circuit.nodes:\n",
    "        layer = node[0]\n",
    "        layer_counts[layer] = layer_counts.get(layer, 0) + 1\n",
    "    \n",
    "    print(f\"  Layer distribution:\")\n",
    "    for layer in sorted(layer_counts.keys()):\n",
    "        print(f\"    Layer {layer:2d}: {layer_counts[layer]} nodes\")\n",
    "    \n",
    "    # Average connectivity\n",
    "    if circuit.nodes:\n",
    "        connectivity = len(circuit.edges) / len(circuit.nodes)\n",
    "        print(f\"  Average connectivity: {connectivity:.2f} edges/node\")\n",
    "    \n",
    "    # Circuit depth\n",
    "    if circuit.nodes:\n",
    "        min_layer = min(n[0] for n in circuit.nodes)\n",
    "        max_layer = max(n[0] for n in circuit.nodes)\n",
    "        depth = max_layer - min_layer + 1\n",
    "        print(f\"  Circuit depth: {depth} layers (L{min_layer} to L{max_layer})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Export Results\n",
    "\n",
    "Save circuits and analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('/mnt/user-data/outputs/notebook_results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export circuits as JSON\n",
    "circuits_data = []\n",
    "for circuit in circuits:\n",
    "    circuits_data.append({\n",
    "        'name': circuit.name,\n",
    "        'fact_type': circuit.fact_type,\n",
    "        'num_nodes': len(circuit.nodes),\n",
    "        'num_edges': len(circuit.edges),\n",
    "        'attribution_score': circuit.attribution_score,\n",
    "        'nodes': [{'layer': n[0], 'feature': n[1]} for n in circuit.nodes[:20]]\n",
    "    })\n",
    "\n",
    "with open(output_dir / 'circuits.json', 'w') as f:\n",
    "    json.dump(circuits_data, f, indent=2)\n",
    "\n",
    "print(f\"✓ Results exported to {output_dir}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - circuits.json\")\n",
    "print(f\"\\nYou can now view these files in the outputs directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Interactive Exploration\n",
    "\n",
    "Try your own examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your own factual prompt\n",
    "custom_clean = \"The Great Wall of China is in Asia\"  # Your fact here\n",
    "custom_corrupted = \"The Great Wall of China is in Europe\"  # Corrupted version\n",
    "\n",
    "print(f\"Testing custom prompt:\\n\")\n",
    "print(f\"Clean: {custom_clean}\")\n",
    "print(f\"Corrupted: {custom_corrupted}\\n\")\n",
    "\n",
    "# Test across layers\n",
    "print(\"Layer effects:\")\n",
    "for layer_idx in range(0, num_layers, 4):\n",
    "    effect = discovery.attribution_graph.activation_patching(\n",
    "        custom_clean, custom_corrupted, layer_idx, -1\n",
    "    )\n",
    "    print(f\"  Layer {layer_idx:2d}: {effect:.4f}\")\n",
    "\n",
    "print(\"\\nTry changing the prompts above and re-running this cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. ✓ Loaded Gemma 2B and initialized circuit discovery\n",
    "2. ✓ Created a dataset of factual prompts\n",
    "3. ✓ Tested attribution methods\n",
    "4. ✓ Trained sparse autoencoders\n",
    "5. ✓ Discovered factual recall circuits\n",
    "6. ✓ Visualized circuits\n",
    "7. ✓ Tested hypotheses about features\n",
    "8. ✓ Analyzed circuit properties\n",
    "9. ✓ Exported results\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore more fact types\n",
    "- Test on larger datasets\n",
    "- Refine SAE training\n",
    "- Investigate circuit overlap\n",
    "- Try different models\n",
    "\n",
    "## References\n",
    "\n",
    "- [Mechanistic Interpretability](https://transformer-circuits.pub/)\n",
    "- [Sparse Autoencoders](https://arxiv.org/abs/2309.08600)\n",
    "- [Attribution Patching](https://arxiv.org/abs/2310.10348)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
